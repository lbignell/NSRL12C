14/11/9
- Copied contents from NSRL13C.
- The intent of this simulation is to replicate the experiment carried out in
  2012 with the reflective and unreflective tubs.

Things to change:

Geometry: Hodoscopes, detectors, detector wall properties of reflective tub.
  	  I can use technical drawings but I may still need to rely on David.
Physics: Should not change.
Sensitive Detectors: I'll need to make 2 LS volumes sensitive, and assign the
	  	     PMTup and PMT down SDs to the new PMTs.
Run Action: Probably needs changing to reflect new SDs, etc.
Primary Generator: Need to reproduce the beam, and have a user-settable variable
		   that modifies the height of the beam entry point.

- Created PGAMessenger class to handle adjusting the height of the mean beam
  position. Tested working.
- I'm on the plane at the moment, so I'll need to wait until I have internet to
  get the technical drawings and can implement the geometry changes.

14-12-4
- There are some notes pasted on the back of notebook, page 29. These spell out
  the distances between the hodoscopes/tubs. The notes also indicate that the
  beam hit the centre of the tubs.
- I should git this code to both keep track of changes and make it accessible 
  between my various machines...

14-12-5
- Status to date:
  - Completed the geometry section of DetectorConstruction.
  - Put code into a Git repository and pushed to GitHub.

- Testing teflon tub optical properties. The optical photons need to traverse
  the white teflon if Cerenkov light is to be produced in it. So the way that I
  set up the optical interface must change.
  --> In my previous code I just had a uniform reflectance from the box that was
      implemented in SensitiveDetector.
  --> I can still do this for the black teflon box.
  --> However for the white one I must use the Geant4 optical surface models.
      What seems to work is having a ground dielectric-dielectric interface on
      the liquid/teflon barrier, and a ground dielectric-metal interface on the
      teflon/air barrier. I can then adjust the reflectance by modifying the
      attenuation length in the PFTE.
      --> I've implemented this.

14-12-9
- To do:
  - Modify my RunAction to collect the following info:*DONE*
    - Incident primary kinetic energy for T1/T2.
    - Edep in T1/T2/H1/H2/H3.
    - Vertex X-Y of primary (implement in T1).
    - Whether the primary particle entered T1/T2/H1/H2/H3.
    - Total # opt photons in T1/T2.
    - Opt photon energy on production; T1/T2.
    - Opt photon creator process; T1/T2.
    - Opt photon energy at PMT (+ measured); winT1/winT2.
    - Num Opt photons at PMT (+ measured); winT1/winT2.
  - Propagate these changes through the program. *DONE*
  - Recalculate the photon position on the PC surface for the PMTwin class. I
    should also enable setting the T1 and T2 PMT effective areas as different
    values.*DONE*
  - Modify the PGA to reflect the beam profile used in NSRL12C.
    -> I can't find any relevant docs. I'll ask David when he's back from 
       holidays. I'll proceed for now assuming the parameters are the same as
       for NSRL13A.
  - Add Rayleigh scattering length to teflon.*DONE*

- Making the Rayleigh scattering length too short causes excessively long
  compute times. I can improve this situation by:
  - Modify the Rayleigh scattering length to a longer value to make things
    easier.
  - Make the attenuation length a bit shorter (if it actually is short).
  - Once I've got the optical properties sorted; remove the G4OpticalSurface
    on tub 1.
  - I can maybe gain a few-fold speedup by killing some fraction of the optical
    photons and increasing the PMT QE by a corresponding fraction.
  - Figure out how to run multithreaded. Running on the RACF may then work.

2014-12-10
- Kinetic energy sometimes (~% level) appears to be higher than the incident 
  particle energy! It is very obviously multiple particles being counted at
  once. I should check my initialization for this. The other quantities don't
  appear to exhibit the same error (thankfully). -> Mostly fixed, a full fix
  would require more effort than I can justify. Results should be correct for
  >99% of events and no other quantities are affected.
- NumPhotons_PMTT2 appears to have a type error. I will be getting this when I
  call it from SensitiveDetector, so I should check that call and the method
  that is called.
  -> Should be fixed now. Is not in fact. I need to look into this further...

- Implementing more realistic teflon optical properties; based on this thesis:
  https://smartech.gatech.edu/bitstream/handle/1853/22686/li_qinghe_200805_mast.pdf
  -> Simulation runs even slower: 1 evt = 2:39.522, 2 evts = 5:38.081.
  -> A single event takes > 1 minute!

- To speed things up; I'm going to implement a simpler optical model.
  -> I'll use the measured attenuation coefficient of ~1m, and NO scatter.
  -> I'll use the nominal teflon refractive index of 1.36.
  -> I'll not model Rayleigh scatter.
  -> I'll use the G4 optical surface type as a ground (diffusive scatter) metal
     (perfect scatter) between the teflon and the air interface.
- The above measures will allow Ckov production in the teflon and semi-realistic
  scattering of light from teflon. It will allow the Ckov produced in the teflon
  to directly illuminate the PMT, but this can happen in the water anyway.
  -> New run time: 2 evts = 13.727, 1 evt = 9.393 -> 4 secs/evt

- Results:
  - TUB 1
  -> The 475 MeV data agree surprisingly well with the measured results for a
     first pass (~10.5 PE measured (RMS 5.7) vs 13.3 PE simulated (RMS 6.2)).
  -> The 2 GeV results are further off: 204 PE (RMS 23.7) measured, 346 PE (RMS
     32.9) simulated. At least the simulated results exhibit greater light yield
     than the measured results at both energies in T1.
  - TUB 2
  -> 475 MeV data are both consistent with ~ <single PE.
  -> 2GeV: 3.5 PE (5.1 RMS) measured, 2.2 PE (3.3 RMS) simulated. Not much to go
     on but it appears that the black teflon may need some reflectance...

- To make the code more portable; I've made a requirement that the location of
  the data files be set using the $DATAFILES environment variable.

2014-12-11
- Modified PGA so that the beam is still sampled from the same distribution but
  only accepts events that are within 1 mm of the front hodoscope.
- Running a scan over the beam height relative to the centre of the tub.
- Fixed a bug that prevented me changing the particle gun energy (in 
  PrimaryGeneratorAction::GeneratePrimaries. A side-effect is that there is no
  longer any spread in the beam energy. I don't think this is consequential.

- As the simulation is quite slow; I'm looking into the multithreading. A naive
  use of G4MTRunManager gives an error when building the PhysicsList. The error
  is: 
  "Size of G4ProcessVector is inconsistent between master and worker threads
   for the particle <anti_He3>. size of G4ProcessVector for worker thread is
   19 while masther thread is 9."
  Removing hadronic processes from the physics list removes this error, but that
  is not a satisfactory solution. The MT migration page says you should be sure
  to define G4GenericIon in the particle definition; however doing this does not
  fix the problem.
  There are also several changes to my user action classes (PGA, DC, SD, maybe
  others, see the website:
  https://twiki.cern.ch/twiki/bin/view/Geant4/QuickMigrationGuideForGeant4V10
  In particular (not on page above), I'll need to use a thread lock when I pass
  data from the sensitive detector to the run action at the end of event, as
  RunAction is shared between threads and sensitive detectors are thread-local.
  -> I should do this at some point; but for now I'll content myself with just
     running single threaded to get some quick results.

- Fixed an annoying bug in my DetectorMessenger that restricted the beam height
  to >0.

- Running with 2 GeV and 475 MeV data for several beam heights (-5 cm to + 5 cm
  in 1 cm steps).
  -> Results are actually in pretty good agreement for much of the range;
     probably because of the different reflective model.
     - T1: 2GeV measured 204 PE, best sim fit @ ~2 cm (+/- a few cm, identical
       	   within uncerts. 475 MeV measured 10.2 PE, max simulated 6.4 PE. This 
	   is much worse agreement than previously; and may be due to the lack
	   of energy spread (I turned that off). TO DO: TURN ON ENERGY SPREAD
	   IN 475 MEV DATA AND SEE IF IT MAKES A DIFFERENCE.
     - T2: 2 GeV measured 3.5 PE; strong variation with beam height for 
       	   simulation; best fit at 2 cm (not 3, maybe 1; 2.9 PE @2cm). 475 MeV
	   was consistent with <1 PE, simulation is same (mean = 0.15).

- Going to do higher resolution run overnight for 2 GeV and 475 MeV.
  -> Changed PGA so that the beam now has to fall exactly within the hodoscope
     area to make more efficient.
  -> Running for 1K events per height, from -0.5cm, to 4 cm, 0.5 cm increments.

2014-12-12
- Got decent agreement with the water; except for the 475 MeV data.
  - I tried 476 MeV data (~ how much the beam may be off by) and the discrepancy
    remains. I don't know why the agreement is so poor; perhaps because of the
    handling of the reflectance in the teflon tub?

- Pressed on to look at WbLS; 1% scintillator:
  - 475 MeV, T1: Measured 111 PE; simulated 152 PE.
  - 475 MeV, T2: Measured 15.7 PE (Gaussian-fitted), sim 15.3 PE (also fitted).
  - 2 GeV, T1: Measured 246 PE; simulated 326.6 PE.
  - 2 GeV, T2: Measured 27.6 PE (Gaussian-fitted); sim 27.8 PE (also fitted).
  - 210 MeV, T1: Measured 180 PE; simulated 238 PE.
  - 210 MeV, T2: Meas 28.2 PE (Gaussian-fitted), sim 29.7 (fitted) or 29.8 PE.

  -> T2 results agree quite well with the measurements (within 5%). The T1
     results give poor agreement that is very consistent (each 32% off).

- Going to try running o'night with 0.4% scintillator.
  -> I've changed the WbLS fraction and scaled the scintillation yield.
  -> Running 10K events; should take 25 hrs.

2014-12-13
- 0.4% scintillator results:
  - 2 GeV, T1: measured 220 PE, simulated 267 PE.
  - 2 GeV, T2: measured 18.9 PE, simulated 23.3 PE.
  - 475 MeV, T1: measured 42.1, simulated 71.1 PE.
  - 475 MeV, T2: measured 4.08 PE, simulated 7.13 PE.
  - The above results are rubbish; just realised that I made the WbLS fraction
    at 0.04%, rather than 0.4%!!!

- Also scaled the WLS absorption length by WbLSFraction/0.0099, running again.

2014-12-15
- Running with REAL 0.4% scintillator, scaled abs length...
  - 2 GeV, T1: measured 221 PE, simulated 142 PE.
  - 2 GeV, T2: measured 18.9 PE, simulated 21.3 PE.
  - 475 MeV, T1: measured 42.1, simulated 37.8 PE.
  - 475 MeV, T2: measured 4.08 PE, simulated 6.52 PE.
  - 210 MeV, T1: measured 36.6 PE, simulated 50.6 PE.
  - 210 MeV, T2: measured 5.25 PE, simulated 11.94 PE.

2014-12-16
- To Do:
  - Make scintillator fraction settable using DetectorMessenger.
    -> Done: Shares same limitations as setting water/WbLS fraction (see below).
  - Make liquid material water/WbLS, user-settable with DetectorMessenger.
    -> Done: set with /CustomCommands/det/isWater true (or false). Default is
       	     water. Need to run /CustomCommands/det/update. Actually, NO, it
	     does NOT work! It appears to Seg Fault because the physics tables,
	     etc. aren't being rebuilt... It works OK if it is used at the start
	     of a run; before tables, etc. are built.
	     On reflection; I think being restricted to setting the material at
	     the start of a session isn't so bad that I need to spend more time
	     on fixing this...
  - Paralellise code, get it to work with hadronic interactions turned on.

2014-12-17
- The problems with seg-faulting upon changing the materials have been worked
  around; I've just written a bash script to change the parameters in the
  macro that calls Geant4, and making a new session for each parameter change.
  -> Works...

2014-12-18
- Figured out why the multithreading was stuffing up on hadronic physics; the
  PhysicsList appears to  be a shared-thread class, except for
  ConstructProcess() and ConstructParticle() methods, which are local.
  I was using a vector to store the hadronic processes but wasn't clearing it
  between instanciations. Clearing it prior to (and following) filling it fixes
  the crash on this process, moving the crash to PrimaryGeneratorAction (for
  which I can just follow the instructions on the migration wiki).
  -> Actually, I've realised there may be some race condition between threads
     trying to access/clear the process vector at the same time; I'm just using
     local variables for everything now...

- OK, I figured it out after banging my head against the keyboard for a bit:
  -> Need a mutex lock when I call RunAction::TallyEvtData, to avoid overwriting
     the branch variables prior to filling the tree.
  -> I also need to make the root file, tree, and all branch variables static;
     so that 1. the file is not overwritten, 2. only 1 tree is written to file,
     and 3. the addresses of the branches stay constant across threads.

- Running multithreaded on my Ubuntu desktop definitely shows both cores working
  on the simulation. I can run 1000x events without any hiccups.

- Testing how the code running time on RACF vs # of cores.
  -> Discovered bug: when I access the ExEmData.root file; I need to make the
     code threadsafe, to avoid multiple threads reading the file at the same
     time (I get an occasional seg fault from this).

- Code breaks when I do /CustomCommands/det/update.
  I'll look into this tomorrow...

2014-12-19
- Fixing the error when the geometry is updated...
  -> The problem is that when the geometry is updated, the Sensitive Detector
     manager already has the current SDs registered. I then reinitialize the
     geometry and try to add some more SDs with the same name, causing a G4 to
     throw an error or a seg fault; depending on how the geometry is
     reinitialized.
  -> My workaround:
     - Get the SDmanager pointer and de-activate all of the current SDs.
     - Reinitialize the geometry.
  -> Important points/limitations:
     - This approach only works if DetectorConstruction::UpdateGeometry() is
       called from the pre-init state; so I've removed the run manager's
       initialize command from main().
     - Because of the above point; all of my macros must do their geometry
       changes, then call /run/initialize, prior to any running.
     - I still can't run then make a change without seg-faulting.
     - Based on my googling around about this issue; updating the geometry is 
       not one of Geant4's strong suits (especially if there is a change to
       materials involved). There may be a solution in individually modifying
       the physical/logical volume pointers; but at the moment it is working and
       will do me...

- To Do:
  - Measure absorption lengths of 0.4% LS and pure LS (or maybe use DB LS?).
    ->DONE.
  - Modify DetectorConstruction and DetectorMessenger to make a switch for
    changing between the measured absorption data sets, instead of just scaling.
    ->This actually didn't require a DetectorMessenger modification; I just 
      check whether the WbLS fraction used is 100%, 1%, or 0.4%, and run it with
      the data if I have it, otherwise I scale from 1% WbLS.
  - A reminder about the fundamental limitation of my model:
    I'm bundling WbLS absorption and scattering in together as a single WLS
    cross-section! This means that the portion of photons that would be
    scattered are instead wavelength shifted (with some QY). This apparently
    hasn't had a big effect on the results to date, but it may be one reason why
    the white tub, for instance, doesn't agree very well. (Though I can't really
    claim that while I'm getting poor ageement for the water).

2014-12-23
- Added a lock on the ROOT file readout, because I'm getting seg faults at
  around that point in my program, hopefully it will stop them...

- Added another change to DetectorConstruction: if the WbLS fraction == 1 (ie.
  pure LS), I declare the WbLS material as having only one component (LS) rather
  than 2.

- Running pure LS takes a VERY long time; I'm considering turning off the T1
  simulation of optical photons in favour of being not slow!
  - To give some idea of how slow; running 10 events in paralell across 10 cores
    takes about 10 minutes! (The first event seemed to finish after ~5 mins, the
    last one finished after ~10 mins). This means that to run 1000 events; it
    would take ~ 5 days, even using 10 cores!
    -> That was only for 475 MeV protons!!

- Had a look at using the cluster to access more cores.
  - The cluster uses condor (same as ANSTO's cluster IIRC, at least it seems
    familiar).
    -> I have problems getting the test script to execute; the node reports not
       being able to find /data5/lbne/lbignell/github/NSRL12C/NSRL12C-build
       Possibly the NSRL12C is not NFS? The default location of the output
       is to /experiment/u/user...
  - I may come back to this if I need to but for now I'll give it a rest; using
    12 of the test node's 16 cores should suffice for all but the pure LS -- I
    may be able to get away with turning off the PTFE reflectance in T1 for that
    simulation...

2014-12-24
- Testing the output from the multithreaded code reveals that it does NOT work
  as expected. There are way too many photons.
  -> My guess is that this is because of the way the data are written to the
     root file; or in the way the data are collected from the other SDs (in 
     which case I may be able to fix it by making my root file output extern).

- Whatever the cause of the cock up, I don't think it's worth the time to chase 
  down the source of the problem. I'll just run it without multithreading.
  (It will be slow but I have all Christmas!).

- Reverting back the changes to incorporate 0.4% and 100% WbLS data.
